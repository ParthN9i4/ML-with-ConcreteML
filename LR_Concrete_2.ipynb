{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthN9i4/ML-with-ConcreteML/blob/main/LR_Concrete_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZBvMmyWi3MZm",
        "outputId": "ab917401-b6ad-41d0-d011-8cc789a9024e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting concrete.ml\n",
            "  Downloading concrete_ml-1.4.1-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0.0,>=1.23.5 (from concrete.ml)\n",
            "  Downloading boto3-1.34.72-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brevitas==0.8.0 (from concrete.ml)\n",
            "  Downloading brevitas-0.8.0-py3-none-any.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.3/357.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.07.22 (from concrete.ml)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting concrete-python==2.5.1 (from concrete.ml)\n",
            "  Downloading concrete_python-2.5.1-cp310-cp310-manylinux_2_28_x86_64.whl (65.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<0.104.0,>=0.103.2 (from concrete.ml)\n",
            "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython==3.1.41 (from concrete.ml)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hummingbird-ml[onnx]==0.4.8 (from concrete.ml)\n",
            "  Downloading hummingbird_ml-0.4.8-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.6/164.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.23.5 (from concrete.ml)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.13.1 (from concrete.ml)\n",
            "  Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxoptimizer==0.3.10 (from concrete.ml)\n",
            "  Downloading onnxoptimizer-0.3.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.6/671.6 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime==1.13.1 (from concrete.ml)\n",
            "  Downloading onnxruntime-1.13.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from concrete.ml) (3.20.3)\n",
            "Collecting pytest-json-report==1.5.0 (from concrete.ml)\n",
            "  Downloading pytest_json_report-1.5.0-py3-none-any.whl (13 kB)\n",
            "Collecting scikit-learn==1.1.3 (from concrete.ml)\n",
            "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from concrete.ml)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools==65.6.3 (from concrete.ml)\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skops==0.5.0 (from concrete.ml)\n",
            "  Downloading skops-0.5.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skorch==0.11.0 (from concrete.ml)\n",
            "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.13.1 (from concrete.ml)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from concrete.ml) (4.66.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.36.0 in /usr/local/lib/python3.10/dist-packages (from concrete.ml) (4.38.2)\n",
            "Collecting typing-extensions==4.5.0 (from concrete.ml)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting uvicorn<0.22.0,>=0.21.0 (from concrete.ml)\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.6.2 (from concrete.ml)\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brevitas==0.8.0->concrete.ml) (24.0)\n",
            "Collecting dependencies==2.0.1 (from brevitas==0.8.0->concrete.ml)\n",
            "  Downloading dependencies-2.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: importlib-resources>=6.1 in /usr/local/lib/python3.10/dist-packages (from concrete-python==2.5.1->concrete.ml) (6.4.0)\n",
            "Requirement already satisfied: networkx>=2.6 in /usr/local/lib/python3.10/dist-packages (from concrete-python==2.5.1->concrete.ml) (3.2.1)\n",
            "Collecting z3-solver>=4.12 (from concrete-python==2.5.1->concrete.ml)\n",
            "  Downloading z3_solver-4.13.0.0-py2.py3-none-manylinux2014_x86_64.whl (57.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython==3.1.41->concrete.ml)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from hummingbird-ml[onnx]==0.4.8->concrete.ml)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxconverter-common>=1.6.0 (from hummingbird-ml[onnx]==0.4.8->concrete.ml)\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from hummingbird-ml[onnx]==0.4.8->concrete.ml) (5.9.5)\n",
            "Collecting onnxmltools<=1.11.0,>=1.6.0 (from hummingbird-ml[onnx]==0.4.8->concrete.ml)\n",
            "  Downloading onnxmltools-1.11.0-py2.py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting skl2onnx<=1.12.0,>=1.7.0 (from hummingbird-ml[onnx]==0.4.8->concrete.ml)\n",
            "  Downloading skl2onnx-1.12-py2.py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.3/279.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime==1.13.1->concrete.ml)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->concrete.ml) (24.3.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->concrete.ml) (1.12)\n",
            "Requirement already satisfied: pytest>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from pytest-json-report==1.5.0->concrete.ml) (7.4.4)\n",
            "Collecting pytest-metadata (from pytest-json-report==1.5.0->concrete.ml)\n",
            "  Downloading pytest_metadata-3.1.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->concrete.ml) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.3->concrete.ml) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from skops==0.5.0->concrete.ml) (0.20.3)\n",
            "Requirement already satisfied: tabulate>=0.8.8 in /usr/local/lib/python3.10/dist-packages (from skops==0.5.0->concrete.ml) (0.9.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->concrete.ml)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->concrete.ml)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->concrete.ml)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->concrete.ml)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->concrete.ml) (0.43.0)\n",
            "Collecting botocore<1.35.0,>=1.34.72 (from boto3<2.0.0,>=1.23.5->concrete.ml)\n",
            "  Downloading botocore-1.34.72-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.23.5->concrete.ml)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.23.5->concrete.ml)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.104.0,>=0.103.2->concrete.ml) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi<0.104.0,>=0.103.2->concrete.ml) (2.6.4)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete.ml) (3.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete.ml) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete.ml) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete.ml) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete.ml) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.0->concrete.ml) (0.4.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.22.0,>=0.21.0->concrete.ml) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn<0.22.0,>=0.21.0->concrete.ml)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi<0.104.0,>=0.103.2->concrete.ml) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi<0.104.0,>=0.103.2->concrete.ml) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi<0.104.0,>=0.103.2->concrete.ml) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.72->boto3<2.0.0,>=1.23.5->concrete.ml) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.72->boto3<2.0.0,>=1.23.5->concrete.ml) (2.0.7)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython==3.1.41->concrete.ml)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.1->skops==0.5.0->concrete.ml) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of onnxconverter-common to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnxconverter-common>=1.6.0 (from hummingbird-ml[onnx]==0.4.8->concrete.ml)\n",
            "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml) (2.16.3)\n",
            "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pydantic-2.6.2-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.16.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.6.0-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.16.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.14.6 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.14.5 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.5.1-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.6/381.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.14.3 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.5.0-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.5/407.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.14.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.10.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.4.1-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.3/395.3 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pydantic-2.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.4/395.4 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.10.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.6.3 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.2.1-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.4/373.4 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.6.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.2.0-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.2/373.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.1.1-py3-none-any.whl (370 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.0.3-py3-none-any.whl (364 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.0/364.0 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.3.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-2.0.2-py3-none-any.whl (359 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.1/359.1 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.1.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic_core-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi<0.104.0,>=0.103.2->concrete.ml)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3.8.0->pytest-json-report==1.5.0->concrete.ml) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.8.0->pytest-json-report==1.5.0->concrete.ml) (1.4.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.8.0->pytest-json-report==1.5.0->concrete.ml) (2.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.13.1->concrete.ml)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.36.0->concrete.ml) (3.3.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.13.1->concrete.ml) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.72->boto3<2.0.0,>=1.23.5->concrete.ml) (1.16.0)\n",
            "Installing collected packages: z3-solver, typing-extensions, smmap, setuptools, nvidia-cuda-nvrtc-cu11, numpy, jmespath, humanfriendly, h11, dill, dependencies, certifi, uvicorn, starlette, scipy, pytest-metadata, pydantic, onnx, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, gitdb, coloredlogs, botocore, xgboost, scikit-learn, s3transfer, pytest-json-report, onnxruntime, onnxoptimizer, onnxconverter-common, nvidia-cudnn-cu11, gitpython, fastapi, torch, skorch, skops, skl2onnx, boto3, onnxmltools, hummingbird-ml, concrete-python, brevitas, concrete.ml\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.10.0\n",
            "    Uninstalling typing_extensions-4.10.0:\n",
            "      Successfully uninstalled typing_extensions-4.10.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "sqlalchemy 2.0.29 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "bigframes 1.0.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.34.72 botocore-1.34.72 brevitas-0.8.0 certifi-2023.7.22 coloredlogs-15.0.1 concrete-python-2.5.1 concrete.ml-1.4.1 dependencies-2.0.1 dill-0.3.8 fastapi-0.103.2 gitdb-4.0.11 gitpython-3.1.41 h11-0.14.0 humanfriendly-10.0 hummingbird-ml-0.4.8 jmespath-1.0.1 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 onnx-1.13.1 onnxconverter-common-1.13.0 onnxmltools-1.11.0 onnxoptimizer-0.3.10 onnxruntime-1.13.1 pydantic-1.10.14 pytest-json-report-1.5.0 pytest-metadata-3.1.1 s3transfer-0.10.1 scikit-learn-1.1.3 scipy-1.10.1 setuptools-65.6.3 skl2onnx-1.12 skops-0.5.0 skorch-0.11.0 smmap-5.0.1 starlette-0.27.0 torch-1.13.1 typing-extensions-4.5.0 uvicorn-0.21.1 xgboost-1.6.2 z3-solver-4.13.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "numpy",
                  "pkg_resources",
                  "setuptools",
                  "sklearn"
                ]
              },
              "id": "5b9cff8f6b9549e98b1f407a9da5cff7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install concrete.ml"
      ],
      "id": "ZBvMmyWi3MZm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "858205d9",
        "outputId": "c06444b9-5c6e-4fe5-c780-fa3b043956a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from concrete.ml.sklearn import LogisticRegression as ConcreteLogisticRegression"
      ],
      "id": "858205d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67330862"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display"
      ],
      "id": "67330862"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read dataset\n",
        "df = pd.read_csv(\"breast_cancer.csv\")\n",
        "\n",
        "# drop rows with missing values\n",
        "df = df.dropna()\n",
        "# Extract features and labels\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Standardize features\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Generate grid data spanning the same range as X\n",
        "b_min = np.min(X, axis=0)\n",
        "b_max = np.max(X, axis=0)\n",
        "\n",
        "x_test_grid, y_test_grid = np.meshgrid(\n",
        "    np.linspace(b_min[0], b_max[0], 30), np.linspace(b_min[1], b_max[1], 30)\n",
        ")\n",
        "x_grid_test = np.vstack([x_test_grid.ravel(), y_test_grid.ravel()]).transpose()\n"
      ],
      "metadata": {
        "id": "fNRXnpXFWT14"
      },
      "id": "fNRXnpXFWT14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set random seeds to initialize the model weight of the model\n",
        "torch.random.manual_seed(73)\n",
        "random.seed(73)\n",
        "\n",
        "def split_train_test(x, y, test_ratio=0.3, random_state=0):\n",
        "    # And test set\n",
        "    idxs = [i for i in range(len(x))]\n",
        "    random.seed(random_state)  # Set the random seed\n",
        "    random.shuffle(idxs)\n",
        "    # Delimiter between test and train data\n",
        "    delim = int(len(x) * test_ratio)\n",
        "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
        "    #convert y to a tensor\n",
        "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
        "\n",
        "# Assuming 'Class' is the column representing the target variable\n",
        "# Replace 'Class' with the actual name of your target variable if different\n",
        "target_column = 'Class'\n",
        "\n",
        "# Load your DataFrame 'data'\n",
        "data = pd.read_csv(\"breast_cancer.csv\")\n",
        "\n",
        "# Display class distribution\n",
        "class_distribution = data[target_column].value_counts()\n",
        "\n",
        "# Find minority and majority classes\n",
        "minority_class = class_distribution.idxmin()\n",
        "majority_class = class_distribution.idxmax()\n",
        "\n",
        "# Print class distribution and identified minority/majority classes\n",
        "print(\"Class distribution:\")\n",
        "print(class_distribution)\n",
        "\n",
        "print(\"\\nMinority class:\", minority_class)\n",
        "print(\"Majority class:\", majority_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3csWK9KrOB6",
        "outputId": "f4143d86-0193-4cf2-ff19-3a9f34a2d5d0"
      },
      "id": "a3csWK9KrOB6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution:\n",
            "0    444\n",
            "1    239\n",
            "Name: Class, dtype: int64\n",
            "\n",
            "Minority class: 1\n",
            "Majority class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Assuming 'Class' is the column representing the target variable\n",
        "# Replace 'Class' with the actual name of your target variable if different\n",
        "target_column = 'Class'\n",
        "\n",
        "# Load your DataFrame 'data'\n",
        "data = pd.read_csv(\"breast_cancer.csv\")  # Replace with your dataset path\n",
        "\n",
        "# Display class distribution before oversampling\n",
        "print(\"Class distribution before oversampling:\")\n",
        "print(data[target_column].value_counts())\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(target_column, axis=1)\n",
        "y = data[target_column]\n",
        "\n",
        "# Initialize SMOTE with desired sampling strategy\n",
        "# In this case, 'minority' indicates that we want to oversample the minority class\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "\n",
        "# Apply SMOTE to the dataset\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Concatenate the resampled data to create the oversampled DataFrame\n",
        "oversampled_data = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=target_column)], axis=1)\n",
        "\n",
        "# Display class distribution after oversampling\n",
        "print(\"\\nClass distribution after oversampling:\")\n",
        "print(oversampled_data[target_column].value_counts())\n",
        "\n",
        "# Triple the size by repeating the process\n",
        "oversampled_data_tripled = oversampled_data.copy()\n",
        "for _ in range(2):\n",
        "    X_resampled, y_resampled = smote.fit_resample(oversampled_data.drop(target_column, axis=1), oversampled_data[target_column])\n",
        "    oversampled_data = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=target_column)], axis=1)\n",
        "    oversampled_data_tripled = pd.concat([oversampled_data_tripled, oversampled_data], ignore_index=True)\n",
        "\n",
        "# Display class distribution after tripling the size\n",
        "print(\"\\nClass distribution after tripling the size:\")\n",
        "print(oversampled_data_tripled[target_column].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eLDpa7hq67D",
        "outputId": "3e1d5486-8791-46ec-b9dc-cf966ee88fee"
      },
      "id": "1eLDpa7hq67D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before oversampling:\n",
            "0    444\n",
            "1    239\n",
            "Name: Class, dtype: int64\n",
            "\n",
            "Class distribution after oversampling:\n",
            "0    444\n",
            "1    444\n",
            "Name: Class, dtype: int64\n",
            "\n",
            "Class distribution after tripling the size:\n",
            "0    1332\n",
            "1    1332\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#oversampled_data_tripled['Class'].value_counts()\n",
        "df = oversampled_data_tripled\n",
        "print(df['Class'].value_counts())\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "XYuIxNnvq8cj",
        "outputId": "d0a5dbbd-5206-4977-ec73-462e4fca7cf8"
      },
      "id": "XYuIxNnvq8cj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1332\n",
            "1    1332\n",
            "Name: Class, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
              "0                5                        1                         1   \n",
              "1                5                        4                         4   \n",
              "2                3                        1                         1   \n",
              "3                6                        8                         8   \n",
              "4                4                        1                         1   \n",
              "\n",
              "   Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
              "0                  1                            2            1   \n",
              "1                  5                            7           10   \n",
              "2                  1                            2            2   \n",
              "3                  1                            3            4   \n",
              "4                  3                            2            1   \n",
              "\n",
              "   Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
              "0                3                1        1      0  \n",
              "1                3                2        1      0  \n",
              "2                3                1        1      0  \n",
              "3                3                7        1      0  \n",
              "4                3                1        1      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5851ccd-8073-41c3-93c8-977a96d853f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5851ccd-8073-41c3-93c8-977a96d853f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5851ccd-8073-41c3-93c8-977a96d853f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5851ccd-8073-41c3-93c8-977a96d853f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a90449c-2bc8-4137-9491-2a7be82327db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a90449c-2bc8-4137-9491-2a7be82327db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a90449c-2bc8-4137-9491-2a7be82327db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2664,\n  \"fields\": [\n    {\n      \"column\": \"Clump Thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          10,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uniformity of Cell Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uniformity of Cell Shape\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Marginal Adhesion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          5,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Single Epithelial Cell Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          10,\n          7,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bare Nuclei\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8,\n          10,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bland Chromatin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          9,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Normal Nucleoli\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mitoses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          5,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def breast_cancer_data():\n",
        "  global df\n",
        "\n",
        "  #print(df.head())\n",
        "  #print(df['Class'].value_counts())\n",
        "  df['Class'].replace(2,0,inplace=True)\n",
        "  df['Class'].replace(4,1,inplace=True)\n",
        "  grouped = df.groupby('Class')\n",
        "  df = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state = 73).reset_index(drop = True))\n",
        "  print(df.head())\n",
        " #extract labels\n",
        "  X = df.drop('Class',axis = 1)\n",
        "  y = df['Class']\n",
        "\n",
        "  print(df.head())\n",
        "  return split_train_test(x, y)\n",
        "\n",
        "x_train, x_test,y_train, y_test = train_test_split(\n",
        "    X, y, test_size = 0.3, random_state = 73\n",
        ")\n",
        "\n",
        "\n",
        "featuresTrain = x_train\n",
        "targetsTrain = y_train\n",
        "featuresTest = x_test\n",
        "targetsTest = y_test\n",
        "\n",
        "print(\"############# Data summary #############\")\n",
        "print(f\"x_train has shape: {x_train.shape}\")\n",
        "print(f\"y_train has shape: {y_train.shape}\")\n",
        "print(f\"x_test has shape: {x_test.shape}\")\n",
        "print(f\"y_test has shape: {y_test.shape}\")\n",
        "print(\"#######################################\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgefIBOIq_SB",
        "outputId": "6a58e179-4a43-4076-e7bb-f332fcbc18a1"
      },
      "id": "cgefIBOIq_SB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Data summary #############\n",
            "x_train has shape: (478, 9)\n",
            "y_train has shape: (478,)\n",
            "x_test has shape: (205, 9)\n",
            "y_test has shape: (205,)\n",
            "#######################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN1SmNdrUDhr",
        "outputId": "4d914ecf-ab02-4162-99a5-428d8cdce481"
      },
      "id": "CN1SmNdrUDhr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(478, 9)\n",
            "(205, 9)\n",
            "(478,)\n",
            "(205,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter"
      ],
      "metadata": {
        "id": "Gs4wagl5zoGA"
      },
      "id": "Gs4wagl5zoGA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import resource\n",
        "\n",
        "\n",
        "# Function to print resource usage\n",
        "def print_resource_usage():\n",
        "    print(\"Resource usage:\")\n",
        "    print(resource.getrusage(resource.RUSAGE_SELF))\n",
        "    print(\"CPU usage:\", psutil.cpu_percent(), \"%\")\n",
        "    print(\"Memory usage:\", psutil.virtual_memory().percent, \"%\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "# Get resource usage before encryption\n",
        "print(\"Resource usage (before):\")\n",
        "print_resource_usage()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diU9cAfz1t1t",
        "outputId": "1b2cd1ef-f87b-475f-a765-090adf05da9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resource usage (before):\n",
            "Resource usage:\n",
            "resource.struct_rusage(ru_utime=51.916701, ru_stime=5.888459, ru_maxrss=720964, ru_ixrss=0, ru_idrss=0, ru_isrss=0, ru_minflt=103188, ru_majflt=1431, ru_nswap=0, ru_inblock=340088, ru_oublock=144, ru_msgsnd=0, ru_msgrcv=0, ru_nsignals=0, ru_nvcsw=135374, ru_nivcsw=26841)\n",
            "CPU usage: 9.7 %\n",
            "Memory usage: 14.1 %\n",
            "\n"
          ]
        }
      ],
      "id": "diU9cAfz1t1t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the type of X_train\n",
        "print(type(y_train))\n",
        "\n",
        "# Print the type of X_test\n",
        "print(type(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPU2a0cAffYo",
        "outputId": "dcb369db-e76e-41d0-b8ca-5732eee6473a"
      },
      "id": "xPU2a0cAffYo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b209247"
      },
      "source": [
        "### Train and predict using scikit-learn\n",
        "We now train a logistic regression model on the training set using scikit-learn. This model will\n",
        "then be used for performance comparison. The predictions are therefore made on non-encrypted data."
      ],
      "id": "0b209247"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec57fede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b9edc6-1a0a-4de7-f554-abb7741b4582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution in clear: 0.016869638000571285 seconds\n"
          ]
        }
      ],
      "source": [
        "t_start = perf_counter()\n",
        "sklearn_logr = SklearnLogisticRegression()\n",
        "sklearn_logr.fit(x_train, y_train)\n",
        "y_pred_test = sklearn_logr.predict(x_test)\n",
        "t_end = perf_counter()\n",
        "print(f\"Execution in clear: {t_end - t_start} seconds\")"
      ],
      "id": "ec57fede"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "data[\"Class\"] = le.fit_transform(data[\"Class\"])"
      ],
      "metadata": {
        "id": "ed0dI9Znr5ip"
      },
      "id": "ed0dI9Znr5ip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcGTKtzz9qUM",
        "outputId": "5563854c-bb28-4849-f273-28e538c4836e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After executing FHE: \n",
            "Resource usage:\n",
            "resource.struct_rusage(ru_utime=53.92722, ru_stime=5.900607, ru_maxrss=721020, ru_ixrss=0, ru_idrss=0, ru_isrss=0, ru_minflt=103194, ru_majflt=1431, ru_nswap=0, ru_inblock=340088, ru_oublock=184, ru_msgsnd=0, ru_msgrcv=0, ru_nsignals=0, ru_nvcsw=136174, ru_nivcsw=27346)\n",
            "CPU usage: 27.9 %\n",
            "Memory usage: 13.9 %\n",
            "\n",
            "Execution time on cipher: 2.0671779370004515\n",
            "Accuracy in clear  : 97.56%\n",
            "Accuracy in FHE    : 97.56%\n",
            "In clear  : [0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            "In FHE    : [0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0\n",
            " 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0]\n",
            "Similarity: 100.0%\n"
          ]
        }
      ],
      "source": [
        "t_start = perf_counter()\n",
        "\n",
        "X_train = x_train.astype(np.float32)\n",
        "X_test = x_test.astype(np.float32)\n",
        "# Now we train in the clear and quantize the weights\n",
        "model = ConcreteLogisticRegression(n_bits=8)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# We can simulate the predictions in the clear\n",
        "y_pred_clear = model.predict(X_test)\n",
        "#Accuracy on plain data\n",
        "accuracy_clear = accuracy_score(y_test, y_pred_clear)\n",
        "\n",
        "# We then compile on a representative set\n",
        "model.compile(X_train)\n",
        "\n",
        "# Finally we run the inference on encrypted inputs\n",
        "y_pred_fhe = model.predict(X_test, fhe=\"execute\")\n",
        "\n",
        "print(\"After executing FHE: \")\n",
        "print_resource_usage()\n",
        "t_end = perf_counter()\n",
        "print(f\"Execution time on cipher: {t_end - t_start}\")\n",
        "\n",
        "#Accuracy on encrypted data\n",
        "accuracy_fhe = accuracy_score(y_test, y_pred_fhe)\n",
        "\n",
        "print(f\"Accuracy in clear  : {accuracy_clear:.2%}\")\n",
        "print(f\"Accuracy in FHE    : {accuracy_fhe:.2%}\")\n",
        "\n",
        "print(f\"In clear  : {y_pred_clear}\")\n",
        "print(f\"In FHE    : {y_pred_fhe}\")\n",
        "print(f\"Similarity: {(y_pred_fhe == y_pred_clear).mean():.1%}\")"
      ],
      "id": "HcGTKtzz9qUM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "996fbe05"
      },
      "source": [
        "### Train using Concrete ML\n",
        "Training a model using Concrete ML follows the same simple steps as with scikit-learn.\n",
        "\n",
        "Additionally, as for all linear models available in Concrete ML, a user has to set the `n_bits`\n",
        "parameter for initialization. This parameter can either be:\n",
        "- a dictionary composed of `op_inputs` and `op_weights` keys. These parameters are given as\n",
        "    integers representing the number of bits over which the associated data should be quantized.\n",
        "\n",
        "- an integer, representing the number of bits over which each input and weight should be quantized.\n",
        "    Default is 8.\n",
        "\n",
        "A more in-depth explanation about this quantization process used in linear models can be found in\n",
        "[the linear regression notebook](LinearRegression.ipynb)."
      ],
      "id": "996fbe05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06ed91dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "ffffa7a1-6883-40d1-ff9e-d67bb3790521"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Unable to cast from non-held to held instance (T& to Holder<T>) (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for type information)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-385f2e9bfa04>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconcrete_logr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcreteLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconcrete_logr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_parameters)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m# Change to composition in order to avoid diamond inheritance and indirect super() calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;31m# FIXME: https://github.com/zama-ai/concrete-ml-internal/issues/3249\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_parameters\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[safe-super]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFheMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFheMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_parameters)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \u001b[0;31m# Compute the quantization parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_quantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_quantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36m_quantize_model\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0;31m# Retrieve the ONNX graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_onnx_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0;31m# Convert the n_bits attribute into a proper dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36m_set_onnx_model\u001b[0;34m(self, test_input)\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sklearn_model_is_not_fitted_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m         self.onnx_model_ = hb_convert(\n\u001b[0m\u001b[1;32m   1542\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"onnx\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hummingbird/ml/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \"\"\"\n\u001b[1;32m    443\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREMAINDER_SIZE\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextra_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hummingbird/ml/convert.py\u001b[0m in \u001b[0;36m_convert_common\u001b[0;34m(model, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_sparkml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_formatted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_formatted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hummingbird/ml/convert.py\u001b[0m in \u001b[0;36m_convert_sklearn\u001b[0;34m(model, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Convert the Topology object into a PyTorch model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mhb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopology_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhb_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hummingbird/ml/_topology.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(topology, backend, test_input, device, extra_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# Generate the ONNX models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         torch.onnx.export(\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mbatch_trace_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \"\"\"\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     _export(\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             \u001b[0m_validate_dynamic_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m             graph, params_dict, torch_out = _model_to_graph(\n\u001b[0m\u001b[1;32m   1530\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         graph = _optimize_graph(\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_canonicalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m     \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mGLOBALS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_shape_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         _C._jit_pass_onnx_graph_shape_type_inference(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to cast from non-held to held instance (T& to Holder<T>) (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for type information)"
          ]
        }
      ],
      "source": [
        "concrete_logr = ConcreteLogisticRegression(n_bits=8)\n",
        "concrete_logr.fit(x_train, y_train)"
      ],
      "id": "06ed91dd"
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgRlRJBvOTbi",
        "outputId": "7c0c37a9-3044-43f3-d268-00b66e14529c"
      },
      "id": "pgRlRJBvOTbi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(409, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5567e91"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "y_proba_q = concrete_logr.predict_proba(x_test)[:, 1]\n",
        "y_pred_q = concrete_logr.predict(x_test)\n",
        "\n",
        "# Compute the probabilities on the whole domain in order to be able to plot the contours\n",
        "#y_proba_q_grid = concrete_logr.predict_proba(x_grid_test)[:, 1]\n",
        "#y_pred_q_grid = concrete_logr.predict(x_grid_test)"
      ],
      "id": "c5567e91"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd74c5e7"
      },
      "source": [
        "### Compiling the model\n",
        "A Concrete ML model needs to be compiled on a representative data-set (e.g., the training set or a\n",
        "subset of it) in order to later be able to execute its inference in FHE.\n",
        "This compilation process will generate an FHE circuit."
      ],
      "id": "cd74c5e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8f8f95b"
      },
      "outputs": [],
      "source": [
        "fhe_circuit = concrete_logr.compile(x_train)"
      ],
      "id": "b8f8f95b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print resource usage\n",
        "def print_resource_usage():\n",
        "    print(\"Resource usage:\")\n",
        "    print(resource.getrusage(resource.RUSAGE_SELF))\n",
        "    print(\"CPU usage:\", psutil.cpu_percent(), \"%\")\n",
        "    print(\"Memory usage:\", psutil.virtual_memory().percent, \"%\")\n",
        "    print(\"\")\n"
      ],
      "metadata": {
        "id": "UX_2qqt317C6"
      },
      "id": "UX_2qqt317C6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3a13be3"
      },
      "source": [
        "### Generate the keys\n",
        "We can determine the maximum bit width reached within the FHE circuit."
      ],
      "id": "e3a13be3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "debd93ba",
        "outputId": "a8d359af-0b66-4d15-8089-ba74724d092a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating a key for an 19-bit circuit\n"
          ]
        }
      ],
      "source": [
        "print(f\"Generating a key for an {fhe_circuit.graph.maximum_integer_bit_width()}-bit circuit\")"
      ],
      "id": "debd93ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "214d90fb",
        "outputId": "52b25c65-1bad-4e53-a9bf-8bd6c4563658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key generation time: 0.0002 seconds\n"
          ]
        }
      ],
      "source": [
        "time_begin = time.time()\n",
        "fhe_circuit.client.keygen(force=False)\n",
        "print(f\"Key generation time: {time.time() - time_begin:.4f} seconds\")"
      ],
      "id": "214d90fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fb62d52"
      },
      "source": [
        "### Predict in FHE\n",
        "Once the model is compiled, it is possible to execute the inference in FHE using encrypted data."
      ],
      "id": "8fb62d52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc999411",
        "outputId": "dd387468-1f03-436d-b15b-c0819decda9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.0054 seconds per sample\n"
          ]
        }
      ],
      "source": [
        "time_begin = time.time()\n",
        "y_pred_fhe = concrete_logr.predict(x_test, fhe=\"execute\")\n",
        "print(f\"Execution time: {(time.time() - time_begin) / len(x_test):.4f} seconds per sample\")"
      ],
      "id": "bc999411"
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil"
      ],
      "metadata": {
        "id": "6tPUNJQHElM7"
      },
      "id": "6tPUNJQHElM7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8c1d98a"
      },
      "source": [
        "### Accuracy comparison\n",
        "Let's now compare the accuracies from all three models:\n",
        "- the scikit-learn model, computed in the clear using non-encrypted float values\n",
        "- the Concrete ML quantized model, computed in the clear using non-encrypted integers\n",
        "- the Concrete ML FHE model, computed in FHE using encrypted integers"
      ],
      "id": "f8c1d98a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f3236fb",
        "outputId": "f6b8bdf7-8735-4268-ffb1-29c5c4d07e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resource usage:\n",
            "resource.struct_rusage(ru_utime=30.858803, ru_stime=3.363204, ru_maxrss=710748, ru_ixrss=0, ru_idrss=0, ru_isrss=0, ru_minflt=101686, ru_majflt=1375, ru_nswap=0, ru_inblock=318752, ru_oublock=96, ru_msgsnd=0, ru_msgrcv=0, ru_nsignals=0, ru_nvcsw=57557, ru_nivcsw=14796)\n",
            "CPU usage: 15.4 %\n",
            "Memory usage: 13.1 %\n",
            "\n",
            "Sklearn accuracy: 0.9635\n",
            "Quantized Clear Accuracy: 0.9635\n",
            "FHE Accuracy: 0.9635\n",
            "\n",
            "Relative difference between Concrete-ml (quantized clear) and Concrete-ml (FHE) scores: 0.00%\n",
            "Relative difference between scikit-learn (clear) and Concrete-ml (FHE) scores: 0.00%\n"
          ]
        }
      ],
      "source": [
        "sklearn_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "quantized_accuracy = accuracy_score(y_test, y_pred_q)\n",
        "fhe_accuracy = accuracy_score(y_test, y_pred_fhe)\n",
        "print_resource_usage()\n",
        "print(f\"Sklearn accuracy: {sklearn_accuracy:.4f}\")\n",
        "print(f\"Quantized Clear Accuracy: {quantized_accuracy:.4f}\")\n",
        "print(f\"FHE Accuracy: {fhe_accuracy:.4f}\")\n",
        "\n",
        "# Measure the error of the FHE quantized model with respect to the clear quantized model\n",
        "concrete_score_difference = abs(fhe_accuracy - quantized_accuracy)\n",
        "print(\n",
        "    \"\\nRelative difference between Concrete-ml (quantized clear) and Concrete-ml (FHE) scores:\",\n",
        "    f\"{concrete_score_difference:.2f}%\",\n",
        ")\n",
        "\n",
        "# Measure the error of the FHE quantized model with respect to the clear scikit-learn float model\n",
        "score_difference = abs(fhe_accuracy - sklearn_accuracy)\n",
        "print(\n",
        "    \"Relative difference between scikit-learn (clear) and Concrete-ml (FHE) scores:\",\n",
        "    f\"{score_difference:.2f}%\",\n",
        ")"
      ],
      "id": "8f3236fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce3849d6"
      },
      "source": [
        "We can observe that all three accuracy scores are identical, suggesting the impact of quantization\n",
        "is negligible for this model."
      ],
      "id": "ce3849d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fdc39c3-a7d3-4643-9bd7-98b06efc9bd8"
      },
      "source": [
        "## Impact of pre-processing on quantization\n",
        "\n",
        "This section shows the impact of different features distribution on model training.\n",
        "\n",
        "Five datasets are considered:\n",
        "- The raw dataset\n",
        "- Data scaled to \\[-1, 1\\]\n",
        "- Standard scaling\n",
        "- One feature scaled on \\[-1, 1\\] and the other one on \\[-100, 100\\]\n",
        "- One feature scaled on \\[-1, 1\\] and the other one on \\[99, 101\\]"
      ],
      "id": "1fdc39c3-a7d3-4643-9bd7-98b06efc9bd8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "981228dc-7367-4b32-8b58-3e88916b52c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66422c7-4d51-40bc-a802-4a1cce64e051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.10/dist-packages (1.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install utils"
      ],
      "id": "981228dc-7367-4b32-8b58-3e88916b52c5"
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import plot_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "N4a5A2wAyBmr",
        "outputId": "8bc8ab28-5f48-4e3e-b017-aa902c1bb9f2"
      },
      "id": "N4a5A2wAyBmr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'plot_data' from 'utils' (/usr/local/lib/python3.10/dist-packages/utils/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-248c2fd6779f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_data' from 'utils' (/usr/local/lib/python3.10/dist-packages/utils/__init__.py)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0ea54f0-77b1-4b50-a481-9e04c801bc57"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler((-1, 1))\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "id": "d0ea54f0-77b1-4b50-a481-9e04c801bc57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2818540-dc5c-487b-a240-00925c808f79"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train_normalized = scaler.fit_transform(x_train)\n",
        "x_test_normalized = scaler.transform(x_test)"
      ],
      "id": "c2818540-dc5c-487b-a240-00925c808f79"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26269cb3-e6f0-4a3c-960c-fd90155a3b15"
      },
      "outputs": [],
      "source": [
        "x_train_unscaled = x_train_scaled.copy()\n",
        "x_train_unscaled[:, 0] *= 100\n",
        "\n",
        "x_test_unscaled = x_test_scaled.copy()\n",
        "x_test_unscaled[:, 0] *= 100"
      ],
      "id": "26269cb3-e6f0-4a3c-960c-fd90155a3b15"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5e7e32e-fb71-4d3f-b57a-89e44d3d6b60"
      },
      "outputs": [],
      "source": [
        "x_train_shifted = x_train_scaled.copy()\n",
        "x_train_shifted[:, 0] += 100\n",
        "\n",
        "x_test_shifted = x_test_scaled.copy()\n",
        "x_test_shifted[:, 0] += 100"
      ],
      "id": "a5e7e32e-fb71-4d3f-b57a-89e44d3d6b60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a7e6270-23b0-4a9d-9adc-a789e7763f04"
      },
      "outputs": [],
      "source": [
        "n_bits = 5\n",
        "random_state = 0\n",
        "cml_clf = ConcreteLogisticRegression(n_bits=n_bits, random_state=random_state)\n",
        "cml_clf_scaled = ConcreteLogisticRegression(n_bits=n_bits, random_state=random_state)\n",
        "cml_clf_unscaled = ConcreteLogisticRegression(n_bits=n_bits, random_state=random_state)\n",
        "cml_clf_shifted = ConcreteLogisticRegression(n_bits=n_bits, random_state=random_state)\n",
        "cml_clf_normalized = ConcreteLogisticRegression(n_bits=n_bits, random_state=random_state)"
      ],
      "id": "6a7e6270-23b0-4a9d-9adc-a789e7763f04"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68fd6353-e193-4110-8835-a9ba58a5042f"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=2, nrows=5, figsize=(8 * 3, 8 * 4))\n",
        "models = [cml_clf, cml_clf_scaled, cml_clf_normalized, cml_clf_unscaled, cml_clf_shifted]\n",
        "features_trains = [x_train, x_train_scaled, x_train_normalized, x_train_unscaled, x_train_shifted]\n",
        "targets_trains = [y_train, y_train, y_train, y_train, y_train]\n",
        "features_tests = [x_test, x_test_scaled, x_test_normalized, x_test_unscaled, x_test_shifted]\n",
        "targets_tests = [y_test, y_test, y_test, y_test, y_test]\n",
        "names = [\"unchanged\", \"min-max-transformed\", \"normalized\", \"unscaled\", \"shifted\"]"
      ],
      "id": "68fd6353-e193-4110-8835-a9ba58a5042f"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data(ax, features_train, targets_train, features_test, targets_test, model, name):\n",
        "    \"\"\"\n",
        "    Plot the data and decision boundary for a given model on both training and testing data.\n",
        "\n",
        "    Parameters:\n",
        "        ax (matplotlib Axes): Axes object to plot on.\n",
        "        features_train (numpy array): Features of the training data.\n",
        "        targets_train (numpy array): Targets of the training data.\n",
        "        features_test (numpy array): Features of the testing data.\n",
        "        targets_test (numpy array): Targets of the testing data.\n",
        "        model (sklearn model): Trained machine learning model.\n",
        "        name (str): Name of the data transformation.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Plot training data\n",
        "    ax[0].scatter(features_train[:, 0], features_train[:, 1], c=targets_train, cmap='viridis', edgecolors='k')\n",
        "    ax[0].set_title(f'Training Data ({name})')\n",
        "\n",
        "    # Plot decision boundary\n",
        "    plot_decision_boundary(ax[0], features_train, model)\n",
        "\n",
        "    # Plot testing data\n",
        "    ax[1].scatter(features_test[:, 0], features_test[:, 1], c=targets_test, cmap='viridis', edgecolors='k')\n",
        "    ax[1].set_title(f'Testing Data ({name})')\n",
        "\n",
        "    # Plot decision boundary\n",
        "    plot_decision_boundary(ax[1], features_test, model)\n",
        "\n",
        "def plot_decision_boundary(ax, features, model):\n",
        "    \"\"\"\n",
        "    Plot the decision boundary for a given model.\n",
        "\n",
        "    Parameters:\n",
        "        ax (matplotlib Axes): Axes object to plot on.\n",
        "        features (numpy array): Features data.\n",
        "        model (sklearn model): Trained machine learning model.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Create a meshgrid to plot decision boundary\n",
        "    x_min, x_max = features[:, 0].min() - 1, features[:, 0].max() + 1\n",
        "    y_min, y_max = features[:, 1].min() - 1, features[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                         np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "    # Predict on meshgrid points\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plot decision boundary\n",
        "    ax.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "M2OVbthX0tOM",
        "outputId": "7a32a2e6-bf40-4912-b549-b4afd3519460"
      },
      "id": "M2OVbthX0tOM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "The LogisticRegression model is not fitted. Please run fit(...) on proper arguments first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-92962d25d551>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Plot decision boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Plot testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-3cb13d058529>\u001b[0m in \u001b[0;36mplot_decision_boundary\u001b[0;34m(ax, features, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Predict on meshgrid points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, fhe)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFheMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFheMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;31m# Compute the predicted probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfhe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;31m# Retrieve the class with the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, fhe)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFheMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFheMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m         \u001b[0my_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfhe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m         \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X, fhe)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;31m# Here, we want to use SklearnLinearModelMixin's `predict` method as confidence scores are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;31m# the dot product's output values, without any post-processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSklearnLinearModelMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfhe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, fhe)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;31m# Check that the model is properly fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;31m# Ensure inputs are 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/concrete/ml/sklearn/base.py\u001b[0m in \u001b[0;36mcheck_model_is_fitted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \"\"\"\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_not_fitted_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The LogisticRegression model is not fitted. Please run fit(...) on proper arguments first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97ca1cd6-44be-4b15-98db-783cd33eceb9",
        "outputId": "1719fe7f-c5c0-4b6f-cd49-2af713b0ba92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidIndexError",
          "evalue": "(slice(None, None, None), 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-3d16d3852ae3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m ):\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-3cb13d058529>\u001b[0m in \u001b[0;36mplot_data\u001b[0;34m(ax, features_train, targets_train, features_test, targets_test, model, name)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Plot training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training Data ({name})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3807\u001b[0m                 \u001b[0;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m                 \u001b[0;31m#  the TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5923\u001b[0m             \u001b[0;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5924\u001b[0m             \u001b[0;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5925\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5927\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
          ]
        }
      ],
      "source": [
        "for ax, model, features_train, targets_train, features_test, targets_test, name in zip(\n",
        "    axes,\n",
        "    models,\n",
        "    features_trains,\n",
        "    targets_trains,\n",
        "    features_tests,\n",
        "    targets_tests,\n",
        "    names,\n",
        "):\n",
        "    plot_data(ax, features_train, targets_train, features_test, targets_test, model, name)\n",
        "display(fig)"
      ],
      "id": "97ca1cd6-44be-4b15-98db-783cd33eceb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c8e454f-7d89-4c2e-aa8c-8c7ad22fff82"
      },
      "source": [
        "The graph above showcases how the quantization needed for FHE introduced by Concrete ML is affected by transformations of the features.\n",
        "\n",
        "What is showcased is that having either all features enclosed in the same range `[a, b]` or all features following a normal distribution with $\\sigma=1$ and $\\mu=0$ yields better results than non-processed data.\n",
        "\n",
        "This is explained by the fact that all features are quantized using the same parameters, so to have a shared quantized representation in which all features keep some information it's very important to have similar distributions for all features."
      ],
      "id": "7c8e454f-7d89-4c2e-aa8c-8c7ad22fff82"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "execution": {
      "timeout": 10800
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}